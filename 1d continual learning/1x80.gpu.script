#!/bin/bash
# ---------------------------------------------------
# The Advanced Research Computing at Hopkins (ARCH)
# User and Application Support < help@rockfish.jhu.edu >
#
# SLURM script to run the JupyterLab
#
# ---------------------------------------------------
#  INPUT ENVIRONMENT VARIABLES
# ---------------------------------------------------
#SBATCH --job-name=ncwno1dcbayesian
#SBATCH --time=0-04:00:00
#SBATCH --partition=a100
##SBATCH --mem=10G
#SBATCH --signal=USR2
#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=1
#SBATCH --ntasks-per-node=16
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=mzaki4@jhu.edu
#SBATCH --output=Jupyter_lab.job.%j.out
#SBATCH --error=Jupyter_lab.job.%j.err
#SBATCH -A mshiel10

export DIR=/home/mzaki4

# ---------------------------------------------------
#  Set environment
# ---------------------------------------------------

# Get the hostname
current_hostname=$(hostname)

# Change to the directory from which the job was submitted
cd "$SLURM_SUBMIT_DIR"

module load anaconda3/2024.02-1
conda activate /home/mzaki4/scratchmshiel10/mzaki4/bayesian_mpp

# Run the Python script
# python -u ncwno_1d_continual_foundation_bayesian.py > out-2.txt 2> err-2.txt 

# python -u compare_models.py > out-3.txt 2> err-3.txt 

python -u ncwno_1d_continual_foundation.py > out_normal.txt 2> err_normal.txt